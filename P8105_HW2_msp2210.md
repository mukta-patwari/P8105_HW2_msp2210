P8105_HW2_msp2210
================
Mukta Patwari
2025-09-23

## Set-up

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.2
    ## ✔ ggplot2   4.0.0     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(haven)
library(readxl)
```

## Problem 1

Cleaning ‘pols-month’ dataset

``` r
pols_month_df =
  read_csv("fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names () %>% 
  separate(
    mon, into = c("year", "month", "day"),
    sep = "-"
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)]
  ) %>% 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) %>% 
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Cleaning ‘snp’ dataset

``` r
snp_df =
  read_csv("fivethirtyeight_datasets/snp.csv", 
      col_types = cols(date = col_date(format = "%m/%d/%y"))) %>% 
  janitor::clean_names() %>% 
  separate(
    date, into = c("year", "month", "day"),
    convert = TRUE,
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.character(year)
  ) %>% 
  select (-day)
```

Cleaning ‘unemployment’ dataset

``` r
unemployment_df =
  read_csv("fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) %>% 
  mutate(
    month = str_to_title(month),
    year = as.character(year)
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merging the ‘pols-month’ and ‘snp’ datasets together

``` r
merged_pols_snp =
  left_join(pols_month_df, snp_df, by = c("year", "month"))
```

Merging the new dataset with ‘unemployment’

``` r
merged_pols_snp_unemployment =
  left_join(merged_pols_snp, unemployment_df, by = c("year", "month"))
```

The cleaned ‘pols-month dataset’ contains 822 rows and the following 9
variables: year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem,
rep_dem, president. This dataset relates to politicians in the U.S.,
like what position they hold (presidential or in Congress), and their
party affiliation, Democrat or Republican. The ‘snp’ dataset refers to
the S&P index, and contains 787 rows with the date of the observation
and the price at closing. The cleaned ‘unemployment’ dataset contains
816 rows and gives the percentage of people unemployed in the month of
each year.

Combining these three data sets creates a merged dataset of 822 rows
with these variables: year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, president, close, percent_unemployed. The years range
from 1947 to 2015, which helps to capture the differences in political
affiliations, stock market events, and unemployment rates. As the
initial ‘snp’ dataset and ‘unemployment’ dataset contained less than 822
observations, there are unfortunately several NAs for the columns of
close and percent_unemployed in the merged dataset.

## Problem 2

Cleaning Mr. Trash Wheel dataset

``` r
mrtrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N709", col_names = TRUE, na = c("NA", ".", "")) %>%
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    year = as.numeric(year)
  ) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  ) %>% 
  mutate(
    trashwheel_name = "Mr. Trash Wheel"
  )
```

Cleaning Professor Trash Wheel dataset

``` r
proftrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M134", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Professor Trash Wheel"
  )
```

Cleaning Gwynnda dataset

``` r
gwynnda_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L351", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Gwynnda Trash Wheel"
  )
```

Merging datasets

``` r
trashwheel_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df)
```

The cleaned dataset contains 1188 observations of trash collected by
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Key variables
include `dumpster` (the dumpster number where the trash is collected)
`weight_tons` (the weight in tons of trash collected), `trashwheel_name`
(shows which trash wheel collected the trash). An interesting variable
is `homes_powered`, which captures how many homes benefitted from the
trash wheel collecting trash to be incinerated and to be converted to
electricity. The total weight in tons of trash collected by Professor
Trash Wheel is 282.26 tons. The total number of cigarette butts
collected by Gwynnda in June of 2022 was 18120.

## Problem 3

Importing and tidying zipcodes dataset

``` r
zipcodes_df =
  read_csv(
    "zillow_data/Zip Codes.csv", 
    na = c("NA", ".", "")
    ) %>%
  janitor::clean_names() %>%
    filter(!(zip_code %in% c(10463, 11201) & county == "New York"))%>%
  select(-state_fips, -county_code, -county_fips, -file_date)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Importing and tidying rental data

``` r
rentalprice_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) %>% 
  rename_with(janitor::make_clean_names, .cols = 1:9) %>% 
  pivot_longer(
    cols = "2015-01-31":"2024-08-31",
    names_to = "date",
    values_to = "rent",
  ) %>% 
  mutate(date = as.Date(date),
  ) %>% 
  rename(zip_code = region_name, county = county_name) %>%
  mutate(
    county = (str_remove(county, "County"))
  ) %>% 
  select(-region_id, -size_rank, -region_type, -state_name, -metro, -county)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merging zip codes and rental price datasets

``` r
zillow_df =
  left_join(
    rentalprice_df, zipcodes_df, by = "zip_code"
    ) %>% 
  relocate(date, state, city, county, zip_code, neighborhood, rent)
```

Finding unique observations

``` r
zillow_df %>% 
  select(zip_code) %>% 
  distinct()
```

    ## # A tibble: 149 × 1
    ##    zip_code
    ##       <dbl>
    ##  1    11368
    ##  2    11385
    ##  3    11208
    ##  4    11236
    ##  5    10467
    ##  6    11373
    ##  7    11226
    ##  8    11207
    ##  9    10025
    ## 10    11214
    ## # ℹ 139 more rows

``` r
zillow_df %>% 
  select(neighborhood) %>% 
  distinct()
```

    ## # A tibble: 43 × 1
    ##    neighborhood              
    ##    <chr>                     
    ##  1 West Queens               
    ##  2 West Central Queens       
    ##  3 East New York and New Lots
    ##  4 Canarsie and Flatlands    
    ##  5 Bronx Park and Fordham    
    ##  6 Flatbush                  
    ##  7 Upper West Side           
    ##  8 Southwest Brooklyn        
    ##  9 Mid-Island                
    ## 10 Sunset Park               
    ## # ℹ 33 more rows

``` r
anti_join(zipcodes_df, rentalprice_df, by = "zip_code") %>%
  select(zip_code, county) %>%
  distinct()
```

    ## # A tibble: 171 × 2
    ##    zip_code county
    ##       <dbl> <chr> 
    ##  1    10464 Bronx 
    ##  2    10474 Bronx 
    ##  3    10475 Bronx 
    ##  4    10499 Bronx 
    ##  5    10550 Bronx 
    ##  6    10704 Bronx 
    ##  7    10705 Bronx 
    ##  8    10803 Bronx 
    ##  9    11202 Kings 
    ## 10    11224 Kings 
    ## # ℹ 161 more rows

The new merged dataset has 17284 observations. There are 149 unique
zipcodes in the dataset, and 43 unique neighborhoods.There are 171
unique zip codes, in the 5 counties/boroughs of the Bronx, Kings,
Manhattan, Queens, and Richmond that were not represented in the Zillow
Rental Price dataset. \[Examples for why these are not included in the
rentalprice_df\]

``` r
pricedrop_df =
  zillow_df %>% 
  filter(month(date) == 1, year(date) %in% c(2020, 2021)) %>%
  mutate(date = as.character(date)) %>%
  pivot_wider(
    names_from = "date",
    values_from = "rent"
  ) %>% 
  rename(
    rent_2020 = "2020-01-31",
    rent_2021 = "2021-01-31"
  ) %>% 
  mutate(price_drop = rent_2020 - rent_2021) %>% 
  arrange(desc(price_drop))

knitr::kable(head(pricedrop_df, 10))
```

| state | city | county | zip_code | neighborhood | rent_2020 | rent_2021 | price_drop |
|:---|:---|:---|---:|:---|---:|---:|---:|
| NY | New York | New York | 10007 | Lower Manhattan | 6334.211 | 5421.614 | 912.5966 |
| NY | New York | New York | 10069 | NA | 4623.042 | 3874.918 | 748.1245 |
| NY | New York | New York | 10009 | Lower East Side | 3406.442 | 2692.187 | 714.2550 |
| NY | New York | New York | 10016 | Gramercy Park and Murray Hill | 3731.135 | 3019.431 | 711.7045 |
| NY | New York | New York | 10001 | Chelsea and Clinton | 4108.098 | 3397.648 | 710.4499 |
| NY | New York | New York | 10002 | Lower East Side | 3645.416 | 2935.113 | 710.3028 |
| NY | New York | New York | 10004 | Lower Manhattan | 3149.658 | 2443.697 | 705.9608 |
| NY | New York | New York | 10038 | Lower Manhattan | 3573.201 | 2875.616 | 697.5853 |
| NY | New York | New York | 10012 | Greenwich Village and Soho | 3628.566 | 2942.344 | 686.2218 |
| NY | New York | New York | 10010 | Gramercy Park and Murray Hill | 3697.284 | 3012.353 | 684.9304 |

The borough with the top 10 price drops between January 2020 and January
2021 was Manhattan/New York. The largest price drop was 912.60 dollars
in the Lower Manhattan neighborhood. Out of these 10 largest price
drops, the lowest was 684.93 dollars in the Gramercy Park and Murray
Hill neighborhood.
