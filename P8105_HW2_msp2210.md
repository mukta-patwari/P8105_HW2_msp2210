P8105_HW2_msp2210
================
Mukta Patwari
2025-09-23

## Set-up

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.2
    ## ✔ ggplot2   4.0.0     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(haven)
library(readxl)
```

## Problem 1

Cleaning ‘pols-month’ dataset

``` r
pols_month_df =
  read_csv("fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names () %>% 
  separate(
    mon, into = c("year", "month", "day"),
    sep = "-"
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)]
  ) %>% 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) %>% 
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Cleaning ‘snp’ dataset

``` r
snp_df =
  read_csv("fivethirtyeight_datasets/snp.csv", 
      col_types = cols(date = col_date(format = "%m/%d/%y"))) %>% 
  janitor::clean_names() %>% 
  separate(
    date, into = c("year", "month", "day"),
    convert = TRUE,
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.character(year)
  ) %>% 
  select (-day)
```

Cleaning ‘unemployment’ dataset

``` r
unemployment_df =
  read_csv("fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) %>% 
  mutate(
    month = str_to_title(month),
    year = as.character(year)
  )
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merging the ‘pols-month’ and ‘snp’ datasets together

``` r
merged_pols_snp =
  left_join(pols_month_df, snp_df, by = c("year", "month"))
```

Merging the new dataset with ‘unemployment’

``` r
merged_pols_snp_unemployment =
  left_join(merged_pols_snp, unemployment_df, by = c("year", "month"))
```

The cleaned ‘pols-month dataset’ contains 822 rows and the following 9
variables: year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem,
rep_dem, president. This dataset relates to politicians in the U.S.,
like what position they hold (presidential or in Congress), and their
party affiliation, Democrat or Republican. The ‘snp’ dataset refers to
the S&P index, and contains 787 rows with the date of the observation
and the price at closing. The cleaned ‘unemployment’ dataset contains
816 rows and gives the percentage of people unemployed in the month of
each year.

Combining these three data sets creates a merged dataset of 822 rows
with these variables: year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, president, close, percent_unemployed. The years range
from 1947 to 2015, which helps to capture the differences in political
affiliations, stock market events, and unemployment rates. As the
initial ‘snp’ dataset and ‘unemployment’ dataset contained less than 822
observations, there are unfortunately several NAs for the columns of
close and percent_unemployed in the merged dataset.

## Problem 2

Cleaning Mr. Trash Wheel dataset

``` r
mrtrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N709", col_names = TRUE, na = c("NA", ".", "")) %>%
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    year = as.numeric(year)
  ) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  ) %>% 
  mutate(
    trashwheel_name = "Mr. Trash Wheel"
  )
```

Cleaning Professor Trash Wheel dataset

``` r
proftrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M134", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Professor Trash Wheel"
  )
```

Cleaning Gwynnda dataset

``` r
gwynnda_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L351", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Gwynnda Trash Wheel"
  )
```

Merging datasets

``` r
trashwheel_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df)
```

The cleaned dataset contains 1188 observations of trash collected by
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Key variables
include `dumpster` (the dumpster number where the trash is collected)
`weight_tons` (the weight in tons of trash collected), `trashwheel_name`
(shows which trash wheel collected the trash). An interesting variable
is `homes_powered`, which captures how many homes benefitted from the
trash wheel collecting trash to be incinerated and to be converted to
electricity. The total weight in tons of trash collected by Professor
Trash Wheel is 282.26 tons. The total number of cigarette butts
collected by Gwynnda in June of 2022 was 18120.

## Problem 3

Importing and tidying zipcodes dataset

``` r
zipcodes_df =
  read_csv("zillow_data/Zip Codes.csv") %>%
  drop_na() %>% 
  janitor::clean_names() %>% 
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y")) %>% 
  rename(date = file_date)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Importing and tidying ZORI data

``` r
zori_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") %>% 
  drop_na() %>% 
  rename_with(janitor::make_clean_names, .cols = 1:9) %>% 
  pivot_longer(
    cols = "2015-01-31":"2024-08-31",
    names_to = "date",
    values_to = "rent",
  ) %>% 
  mutate(
    county_name = str_trim(gsub("County", "", county_name)),
    date = as.Date(date)
  ) %>% 
  rename(zip_code = region_name, county = county_name)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Merging zip codes and ZORI datasets

``` r
zillow_df =
  full_join(
    zori_df, zipcodes_df
    ) %>%
  relocate(date, zip_code, county)
```

    ## Joining with `by = join_by(zip_code, county, date)`

Finding unique observations

``` r
zillow_df %>% 
  select(zip_code) %>% 
  distinct()
```

    ## # A tibble: 179 × 1
    ##    zip_code
    ##       <dbl>
    ##  1    11226
    ##  2    11207
    ##  3    10025
    ##  4    11206
    ##  5    11221
    ##  6    11235
    ##  7    11233
    ##  8    10029
    ##  9    10002
    ## 10    11375
    ## # ℹ 169 more rows

The new merged dataset has 5748 observations. There are 179 unique zip
codes in the dataset…
