---
title: "P8105_HW2_msp2210"
output: github_document
author: "Mukta Patwari"
date: "2025-09-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Set-up
```{r libraries}
library(tidyverse)
library(haven)
library(readxl)
```

## Problem 1

Cleaning 'pols-month' dataset
```{r pols-month}
pols_month_df =
  read_csv("fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names () %>% 
  separate(
    mon, into = c("year", "month", "day"),
    sep = "-"
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)]
  ) %>% 
  mutate(
    president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )
  ) %>% 
  select(-prez_dem, -prez_gop, -day)
```

Cleaning 'snp' dataset
```{r snp}
snp_df =
  read_csv("fivethirtyeight_datasets/snp.csv", 
      col_types = cols(date = col_date(format = "%m/%d/%y"))) %>% 
  janitor::clean_names() %>% 
  separate(
    date, into = c("year", "month", "day"),
    convert = TRUE,
  ) %>% 
  mutate(
    month = month.name[as.numeric(month)],
    year = as.character(year)
  ) %>% 
  select (-day)
```

Cleaning 'unemployment' dataset
```{r unemployment}
unemployment_df =
  read_csv("fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "percent_unemployed"
  ) %>% 
  mutate(
    month = str_to_title(month),
    year = as.character(year)
  )
```

Merging the 'pols-month' and 'snp' datasets together
```{r first-merge}
merged_pols_snp =
  left_join(pols_month_df, snp_df, by = c("year", "month"))
```

Merging the new dataset with 'unemployment'
```{r second-merge}
merged_pols_snp_unemployment =
  left_join(merged_pols_snp, unemployment_df, by = c("year", "month"))
```

The cleaned 'pols-month dataset' contains `r nrow(pols_month_df)` rows and the following `r ncol(pols_month_df)` variables: `r colnames(pols_month_df)`. This dataset relates to politicians in the U.S., like what position they hold (presidential or in Congress), and their party affiliation, Democrat or Republican. The 'snp' dataset refers to the S&P index, and contains `r nrow(snp_df)` rows with the date of the observation and the price at closing. The cleaned 'unemployment' dataset contains `r nrow(unemployment_df)` rows and gives the percentage of people unemployed in the month of each year. 

Combining these three data sets creates a merged dataset of `r nrow(merged_pols_snp_unemployment)` rows with these variables: `r colnames(merged_pols_snp_unemployment)`. The years range from `r min(pull(merged_pols_snp_unemployment, year))` to `r max(pull(merged_pols_snp_unemployment, year))`, which helps to capture the differences in political affiliations, stock market events, and unemployment rates. As the initial 'snp' dataset and 'unemployment' dataset contained less than 822 observations, there are unfortunately several NAs for the columns of close and percent_unemployed in the merged dataset. 

## Problem 2

Cleaning Mr. Trash Wheel dataset
```{r mrtrashwheel}
mrtrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 1, range = "A2:N709", col_names = TRUE, na = c("NA", ".", "")) %>%
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    year = as.numeric(year)
  ) %>% 
  mutate(
    sports_balls = as.integer(round(sports_balls))
  ) %>% 
  mutate(
    trashwheel_name = "Mr. Trash Wheel"
  )
```

Cleaning Professor Trash Wheel dataset
```{r proftrash}
proftrash_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 2, range = "A2:M134", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Professor Trash Wheel"
  )
```

Cleaning Gwynnda dataset
```{r gwynnda}
gwynnda_df =
  read_excel("202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L351", col_names = TRUE, na = c("NA", ".", "")) %>% 
  drop_na(Dumpster) %>% 
  janitor::clean_names() %>%
  mutate(
    trashwheel_name = "Gwynnda Trash Wheel"
  )
```

Merging datasets
```{r trash-wheel-merge}
trashwheel_df =
  bind_rows(mrtrash_df, proftrash_df, gwynnda_df)
```

The cleaned dataset contains `r nrow(trashwheel_df)` observations of trash collected by Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Key variables include `dumpster` (the dumpster number where the trash is collected) `weight_tons` (the weight in tons of trash collected), `trashwheel_name` (shows which trash wheel collected the trash). An interesting variable is `homes_powered`, which captures how many homes benefitted from the trash wheel collecting trash to be incinerated and to be converted to electricity. The total weight in tons of trash collected by Professor Trash Wheel is `r trashwheel_df %>% filter(trashwheel_name == "Professor Trash Wheel") %>% pull(weight_tons) %>% sum()` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 was `r trashwheel_df %>% filter(trashwheel_name == "Gwynnda Trash Wheel", year == 2022, month == "June") %>% pull(cigarette_butts) %>% sum() %>% format(scientific = FALSE)`.

## Problem 3

Importing and tidying zipcodes dataset
```{r zipcodes}
zipcodes_df =
  read_csv(
    "zillow_data/Zip Codes.csv", 
    na = c("NA", ".", "")
    ) %>%
  janitor::clean_names() %>%
  select(-state_fips, -county_code, -county_fips, -file_date) %>% 
  filter(!(zip_code %in% c(10463, 11201) & county == "New York"))
```

Importing and tidying rental data
```{r rental-price}
rentalprice_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) %>% 
  rename_with(janitor::make_clean_names, .cols = 1:9) %>% 
  pivot_longer(
    cols = "2015-01-31":"2024-08-31",
    names_to = "date",
    values_to = "rent",
  ) %>% 
  mutate(date = as.Date(date),
  ) %>% 
  rename(zip_code = region_name, county = county_name) %>%
  mutate(
    county = (str_remove(county, "County"))
  ) %>% 
  select(-region_id, -size_rank, -region_type, -state_name, -metro, -county)
```

Merging zip codes and rental price datasets
```{r zillow}
zillow_df =
  left_join(
    rentalprice_df, zipcodes_df, by = "zip_code"
    ) %>% 
  relocate(date, state, city, county, zip_code, neighborhood, rent)
```

Finding unique observations
```{r}
zillow_df %>% 
  select(zip_code) %>% 
  distinct()

zillow_df %>% 
  select(neighborhood) %>% 
  distinct()

anti_join(zipcodes_df, rentalprice_df, by = "zip_code") %>%
  select(zip_code, county) %>%
  distinct()
```

The new merged dataset has `r nrow(zillow_df)` observations. There are 149 unique zipcodes in the dataset, and 43 unique neighborhoods. 

In the zipcodes dataset, there are 171 unique zip codes for the 5 counties/boroughs of the Bronx, Kings, Manhattan, Queens, and Richmond that were not represented in the Zillow Rental Price dataset. These zip codes are not included in the rental price dataset because they are primarily non-residential neighborhoods and areas. An internet search confirms this fact; for example, Bronx zip-code 10474 refers to the Hunts Point neighborhood, which is a heavily industrial area (`r '[source](https://www.zipwise.com/zip-code/10474)'`). Similarly, the zip code of 11202 in Kings County is where the UN Headquarters, the Chrysler Building, and the Empire State Building are located, which is a non-residential area as well (`r '[source](https://www.zipwise.com/zip-code/11202)'`). As the rental price dataset only captures the rents in residential areas, it does not include the zip codes of these heavily industrial areas/neighborhoods.

```{r}
pricedrop_df =
  zillow_df %>% 
  filter(month(date) == 1, year(date) %in% c(2020, 2021)) %>%
  mutate(date = as.character(date)) %>%
  pivot_wider(
    names_from = "date",
    values_from = "rent"
  ) %>% 
  rename(
    rent_2020 = "2020-01-31",
    rent_2021 = "2021-01-31"
  ) %>% 
  mutate(price_drop = rent_2020 - rent_2021) %>% 
  arrange(desc(price_drop))

knitr::kable(head(pricedrop_df, 10))
```

The borough with the top 10 price drops between January 2020 and January 2021 was Manhattan/New York. The largest price drop was 912.60 dollars in the Lower Manhattan neighborhood. Out of these 10 largest price drops, the lowest was 684.93 dollars in the Gramercy Park and Murray Hill neighborhood.